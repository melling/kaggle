---
title: "An Introduction to Logistic Regression in R"
output:
  html_document:
    toc: true
    depth: 2    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

The goal is to introduce logistic regression in R by solving the Kaggle [Titanic Survivor competition](https://www.kaggle.com/c/titanic).

Don't expect a great score.  There's a lot more to learn but this blog will take you from zero to submission.

```{r message=FALSE, warning=FALSE}
library(tidyverse) # A lot of magic in here
library(GGally)

```

# Read the training data

```{r}
train <- read_csv("../input/train.csv")
```
# Read test data

```{r}
test <- read_csv("../input/test.csv")
```

# Remove a few columns to simplify
```{r}
train <- select(train, -c("Name", "Ticket", "Cabin", "Embarked", "Fare")) # Tidyverse
test <- select(test, -c("Name", "Ticket", "Cabin", "Embarked", "Fare")) # Tidyverse

```

# Convert Survived and Sex to Factors

Categorical variables are converted to factors in R.

In our data, sex is only one of 2 values ('Male', 'Female'), so we treat it differently.  They are categories.

Survived is only 1 or 0, so we also treat it differently. It's also a category variable.

Ignore the details for now. We're only learning enough to get us to the first submission.

```{r}
train$Survived <- as_factor(train$Survived) # Only provided in training data
#contrasts(train$Survived)
table(train$Survived)
```
## Convert Sex to Factor

```{r}
table(train$Sex)
```

```{r}
train$Sex <- as_factor(train$Sex)
test$Sex <- as_factor(test$Sex)

contrasts(train$Sex)
```

```{r}
table(train$Survived)
```
```{r}
table(train$Sex)
```

# Handle Missing Data



## Skim Train

Using the skim() function, we can see that the only missing data is Age, where 177 ages  are missing in the training data.
```{r}
library(skimr)
skim(train)
```
## Skim Test

In the test data, we are missing 86 ages.  We will also replace those with the average.

```{r}
skim(test)
```
Combine train and test data
```{r}
df = bind_rows(train, test)
```

# Get Average Age
```{r}
avg_age <-  mean(df$Age, na.rm=TRUE)
avg_age
```
```{r}
sum(is.na(train$Age))
```

# Replace Missing Ages with the Mean
```{r}
#train[is.na(train$Age)] <-  avg_age
#train %>% replace_na(avg_age)
#replace_na(train, list(Age=avg_age))
train[is.na(train$Age), "Age"] <- avg_age
test[is.na(test$Age), "Age"] <- avg_age
```

# Verify Age was set

We should now get zero rows with na.

```{r}
sum(is.na(train$Age))
```


# Correlation Plot

We won't look at this now, but a correlation pairs plot can be useful when investigating if data is related.

```{r}
ggpairs(train, binwidth=30)
```

# Base Accuracy

In our training data, only 342 survived.

```{r}
table(train$Survived)
```


# Fit the model using all the parameters/features

```{r}
lr.fit = glm(Survived ~ ., data = train, family = binomial)
```

# Summary of the Model
```{r}
summary(lr.fit)
```

# Predict

```{r}
p = predict(lr.fit, type = "response")
```


# Confusion Matrix

```{r}
table(train$Survived, p > 0.5)
```
```
True negative, False Positive
False negative, True Positive
```

Abbreviated like this in matrix form:
```
TN FP
FN TP
```

## Accuracy

Accuracy is the percentage that the model got right: TN + TP divided by the total

The formula: $Accuracy = \frac{TN + TP}{n}$

```{r}

```

```{r}
accuracy = (242 + 460) / nrow(train)
accuracy
```
## Sensitivity

Sensitivity is the true positives divided by all the positives.

The formula: $Sensitivity = \frac{TP}{TP + FP}$

```{r}
sensitivity = 242 / (242 + 100)
sensitivity
```


## Specificity

Specificity is the true negatives divide by all the negatives.

The formula: $Specificity = \frac{TN}{TN + FN}$

```{r}
specificity = 460 / (460 + 89)
specificity
```

# Predict our Test Data

Now we will take the model and use it to predict who survives in the test data.

```{r}
lr.fit.probs = predict(lr.fit, test, type = "response")
```


Add the column to the test data.
```{r}
test$Survived = ifelse(lr.fit.probs > 0.5, 1, 0)

table(test$Survived)
```

We predict only 163 people will survive.

# Generate Kaggle Submission File

```{r}
test %>% 
  select(PassengerId, Survived) %>%
  write.csv("intro_lr_submission.csv", quote = FALSE, row.names = FALSE)
```

The intro submission gives a Kaggle score of 0.74880

# References

- https://www.kaggle.com/jeremyd/titanic-logistic-regression-in-r
- [Factors in R](https://www.youtube.com/watch?v=DWgsyr1CIVU)